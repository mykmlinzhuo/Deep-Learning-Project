[[36m2025-05-26 19:05:53,639[0m][[34mmain.utils[0m][[32mINFO[0m] - Disabling python warnings! <config.ignore_warnings=True>[0m
Seed set to 12345
[[36m2025-05-26 19:05:53,643[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating datamodule <main.module_controlnet_audio.MusdbFolderDatamodule>.[0m
[[36m2025-05-26 19:05:54,205[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating model <main.module_controlnet_audio.Model>.[0m
No module named 'flash_attn'
flash_attn not installed, disabling Flash Attention
Loaded model from /cephfs/shared/linzhuo/models/stable-audio-1.0/model.safetensors
Loaded model_config from /cephfs/shared/linzhuo/models/stable-audio-1.0/model_config.json
[[36m2025-05-26 19:06:43,504[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>.[0m
[[36m2025-05-26 19:06:43,506[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>.[0m
[[36m2025-05-26 19:06:43,511[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>.[0m
[[36m2025-05-26 19:06:43,512[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callback <main.module_controlnet_audio.SampleLogger>.[0m
[[36m2025-05-26 19:06:43,514[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating logger <pytorch_lightning.loggers.wandb.WandbLogger>.[0m
[[36m2025-05-26 19:06:43,517[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating trainer <pytorch_lightning.Trainer>.[0m
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[[36m2025-05-26 19:06:43,538[0m][[34m__main__[0m][[32mINFO[0m] - Logging hyperparameters![0m
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id jr7ye6ya.
wandb: Tracking run with wandb version 0.15.4
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[[36m2025-05-26 19:06:51,526[0m][[34m__main__[0m][[32mINFO[0m] - Starting training.[0m
You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ   â”ƒ Name               â”ƒ Type                                       â”ƒ Params â”ƒ
â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0 â”‚ model              â”‚ ConditionedControlNetDiffusionModelWrapper â”‚  1.9 B â”‚
â”‚ 1 â”‚ model.model        â”‚ DiTControlNetWrapper                       â”‚  1.6 B â”‚
â”‚ 2 â”‚ model.conditioner  â”‚ MultiConditioner                           â”‚  156 M â”‚
â”‚ 3 â”‚ model.pretransform â”‚ AutoencoderPretransform                    â”‚  156 M â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 561 M                                                                                                                         
Non-trainable params: 1.4 B                                                                                                                     
Total params: 1.9 B                                                                                                                             
Total estimated model params size (MB): 7.7 K                                                                                                   
Sample keys: ['bass', 'drums', 'other', 'vocals', 'piano']

Sample keys: ['bass', 'drums', 'other', 'vocals', 'piano']
Sample keys: ['bass', 'drums', 'other', 'vocals', 'piano']
Sample keys: ['bass', 'drums', 'other', 'vocals', 'piano']
Error executing job with overrides: ['exp=train_musdb_controlnet_audio_large_humming', 'datamodule.train_dataset.path=data/musdb18hq/train', 'datamodule.val_dataset.path=data/musdb18hq/test']
Traceback (most recent call last):
  File "/cephfs/shared/linzhuo/stable-audio-controlnet/train.py", line 110, in <module>
    main()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/cephfs/shared/linzhuo/stable-audio-controlnet/train.py", line 87, in main
    trainer.fit(model=model, datamodule=datamodule)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 545, in fit
    call._call_and_handle_interrupt(
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 581, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 990, in _run
    results = self._run_stage()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1034, in _run_stage
    self._run_sanity_check()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1063, in _run_sanity_check
    val_loop.run()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", line 181, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 127, in run
    batch, batch_idx, dataloader_idx = next(data_fetcher)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 127, in __next__
    batch = super().__next__()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 56, in __next__
    batch = next(self.iterator)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 326, in __next__
    out = next(self._iterator)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 132, in __next__
    out = next(self.iterators[0])
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1515, in _next_data
    return self._process_data(data, worker_id)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1550, in _process_data
    data.reraise()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/_utils.py", line 750, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/cephfs/shared/linzhuo/stable-audio-controlnet/main/data/dataset_humming.py", line 178, in collate_fn_piano_to_random_stem
    raise ValueError(f"Sample {i} missing 'humming' key")
ValueError: Sample 0 missing 'humming' key

Traceback (most recent call last):
  File "/cephfs/shared/linzhuo/stable-audio-controlnet/train.py", line 110, in <module>
    main()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/cephfs/shared/linzhuo/stable-audio-controlnet/train.py", line 87, in main
    trainer.fit(model=model, datamodule=datamodule)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 545, in fit
    call._call_and_handle_interrupt(
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 581, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 990, in _run
    results = self._run_stage()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1034, in _run_stage
    self._run_sanity_check()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1063, in _run_sanity_check
    val_loop.run()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", line 181, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 127, in run
    batch, batch_idx, dataloader_idx = next(data_fetcher)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 127, in __next__
    batch = super().__next__()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py", line 56, in __next__
    batch = next(self.iterator)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 326, in __next__
    out = next(self._iterator)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py", line 132, in __next__
    out = next(self.iterators[0])
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1515, in _next_data
    return self._process_data(data, worker_id)
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1550, in _process_data
    data.reraise()
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/_utils.py", line 750, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/root/miniconda3/envs/gsplat/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/cephfs/shared/linzhuo/stable-audio-controlnet/main/data/dataset_humming.py", line 178, in collate_fn_piano_to_random_stem
    raise ValueError(f"Sample {i} missing 'humming' key")
ValueError: Sample 0 missing 'humming' key

wandb: Waiting for W&B process to finish... (failed 1).
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /cephfs/shared/linzhuo/stable-audio-controlnet/logs/wandb/offline-run-20250526_190644-jr7ye6ya
wandb: Find logs at: ./logs/wandb/offline-run-20250526_190644-jr7ye6ya/logs
