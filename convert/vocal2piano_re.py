import os
import torch
import numpy as np
import librosa
import soundfile as sf
import pretty_midi
import torchcrepe
from pydub import AudioSegment
from scipy.ndimage import gaussian_filter1d


# Step 1: è¯»å–å“¼å”±éŸ³é¢‘
input_audio = "/cephfs/shared/linzhuo/stable-audio-controlnet/data/musdb18hq/train/A Classic Education - NightOwl.vocals.mp3"
y, sr = librosa.load(input_audio, sr=16000)
sf.write("vocal.wav", y, sr)

# Step 2: ä½¿ç”¨ torchcrepe æå–ä¸»æ—‹å¾‹ F0
hop_length = int(sr / 100)  # æ¯å¸§ 10ms
fmin, fmax = 50, 550
device = "cuda" if torch.cuda.is_available() else "cpu"

audio_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(0)
pitch, periodicity = torchcrepe.predict(
    audio_tensor, sr, hop_length, fmin, fmax,
    model='tiny', batch_size=128, device=device, return_periodicity=True
)
pitch = pitch.squeeze().numpy()
confidence = periodicity.squeeze().numpy()

# Step 3: ç½®ä¿¡åº¦è¿‡æ»¤ï¼ˆä½ç½®ä¿¡åº¦è®¾ä¸º 0ï¼‰
threshold = 0.3
f0 = np.where(confidence > threshold, pitch, 0.0)
print("éé›¶éŸ³ç¬¦å¸§æ•°é‡ï¼š", np.sum(f0 > 0))

# Step 4: Gaussian å¹³æ»‘ + æ¯ 0.5s é‡‡æ ·ä¸€ä¸ªéŸ³ç¬¦
f0_smoothed = gaussian_filter1d(f0, sigma=1.5)
hop_time = 0.01
interval = int(0.5 / hop_time)  # æ¯ 0.5 ç§’é‡‡æ ·

notes = []
for i in range(0, len(f0_smoothed), interval):
    segment = f0_smoothed[i:i+interval]
    nonzero = segment[segment > 0]
    if len(nonzero) == 0:
        continue
    pitch_hz = np.median(nonzero)
    start = i * hop_time
    end = (i + interval) * hop_time
    notes.append((pitch_hz, start, end))
print("æœ‰æ•ˆéŸ³ç¬¦æ•°ï¼ˆå¹³æ»‘+é‡‡æ ·åï¼‰:", len(notes))

# Step 5: å†™å…¥ MIDI
midi = pretty_midi.PrettyMIDI()
piano = pretty_midi.Instrument(program=0)
for pitch_hz, start, end in notes:
    midi_num = int(np.clip(np.round(pretty_midi.hz_to_note_number(pitch_hz)), 0, 127))
    note = pretty_midi.Note(velocity=100, pitch=midi_num, start=start, end=end)
    piano.notes.append(note)
midi.instruments.append(piano)
midi_path = "melody_re.mid"
midi.write(midi_path)
print(f"âœ… å·²ä¿å­˜ MIDI åˆ°: {midi_path}")

# Step 6: ä½¿ç”¨ fluidsynth æ¸²æŸ“ä¸º WAVï¼ˆç¡®ä¿å®‰è£…ï¼‰
soundfont = "Yamaha_C3_Grand_Piano.sf2"  # è‡ªè¡Œå‡†å¤‡æˆ–æ›¿æ¢è·¯å¾„
wav_out = "melody_re.wav"
os.system(f"fluidsynth -ni {soundfont} {midi_path} -F {wav_out} -r 44100")
if not os.path.exists(wav_out):
    raise FileNotFoundError("âŒ fluidsynth å¤±è´¥ï¼Œæœªç”Ÿæˆ melody.wav")

# Step 7: è½¬ MP3ï¼ˆä½¿ç”¨ pydubï¼‰
mp3_out = "melody_re.mp3"
sound = AudioSegment.from_wav(wav_out)
sound.export(mp3_out, format="mp3")
print(f"ğŸ¹ å®Œæˆï¼è¾“å‡ºé’¢ç´ MP3: {mp3_out}")
